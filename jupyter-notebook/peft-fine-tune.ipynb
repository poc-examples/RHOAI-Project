{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e202d-1fb5-401b-be8a-f112c9c5c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers peft datasets sentencepiece autoawq torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b403925-4bea-47ad-b9f4-ba395d9c4d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cc82b-fa79-419e-9e82-f7e151f90365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../synthetic-data/synthetic_reviews.csv\")\n",
    "\n",
    "# Change Labels to Int\n",
    "label_map = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f358d-646e-4078-9dea-f0524305630c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from awq import AutoAWQForCausalLM\n",
    "\n",
    "local_directory = \"../../models/\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_directory)\n",
    "model = AutoAWQForCausalLM.from_pretrained(\n",
    "    local_directory, \n",
    "    low_cpu_mem_usage=True, \n",
    "    use_cache=False,\n",
    "    local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fbe2a-84b3-48c0-b2c5-7ea864af3eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.half()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2e537-420b-4a62-b094-e5916bef7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Target the attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eda785-44a9-413c-b2c0-c522c79193e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Step 1: Tokenize each text entry in the dataset individually\n",
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    result[\"labels\"] = examples['label']  # Use the existing 'label' column as labels\n",
    "    return result\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b442661-1975-46f2-b262-5e41590657b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(['text', 'label'])\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af030616-9371-4060-8adb-38d1093a2870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenized_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e5b1d-a73c-4a4c-a084-bcffd94eb368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Define a custom data collator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Masked language modeling is not needed for causal LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b0818-f145-497a-999c-8d8da956afe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_steps=500,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ac9f0-326a-4628-819d-e46b28d975f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # Training dataset\n",
    "    eval_dataset=eval_dataset,    # Evaluation dataset\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fdf4a-2603-4b23-8577-80efb4256deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f27781-d536-418c-90b4-d4d7d706519c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1a36b-52da-49e2-8840-7da1c3d77cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"../../trained-model\")\n",
    "tokenizer.save_pretrained(\"../../trained-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298a7a9-101b-4b09-bebd-fde83dbaa2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
